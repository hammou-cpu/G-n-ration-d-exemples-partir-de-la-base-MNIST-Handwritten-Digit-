{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a470cdc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim.models.keyed_vectors'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeyed_vectors\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mKeyedVectors\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclean_text\u001b[39m(text):\n\u001b[0;32m      7\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m    Cleans text by removing HTML tags, non-alphanumeric characters,\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m    extra whitespace, and converting to lowercase.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m        str: The cleaned text.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gensim.models.keyed_vectors'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import gensim.models.keyed_vectors as KeyedVectors\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans text by removing HTML tags, non-alphanumeric characters,\n",
    "    extra whitespace, and converting to lowercase.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to clean.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned text.\n",
    "    \"\"\"\n",
    "\n",
    "    cleaned_text = re.sub(r'<.*?>', '', text)  # Remove HTML tags\n",
    "    cleaned_text = re.sub(r'[^\\w\\s]', ' ', cleaned_text)  # Replace non-alphanumeric with spaces\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()  # Remove extra whitespace\n",
    "    cleaned_text = cleaned_text.lower()  # Convert to lowercase\n",
    "    return cleaned_text\n",
    "\n",
    "def split_into_words(text):\n",
    "    \"\"\"\n",
    "    Splits text into a list of words.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to split.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: The list of words.\n",
    "    \"\"\"\n",
    "\n",
    "    return text.split()\n",
    "\n",
    "def split_into_entences(text):\n",
    "    \"\"\"\n",
    "    Splits text into a list of sentences.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to split.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: The list of sentences.\n",
    "    \"\"\"\n",
    "\n",
    "    return re.split(r'[!?.]\\s+', text)  # Split on sentence endings\n",
    "\n",
    "def get_word_vector(word, word2vec_model):\n",
    "    \"\"\"\n",
    "    Looks up the word vector in the provided Word2Vec model.\n",
    "\n",
    "    Args:\n",
    "        word (str): The word to get the vector for.\n",
    "        word2vec_model (gensim.models.keyed_vectors.KeyedVectors): The Word2Vec model.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The word vector (if found), or None (if not found).\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        return word2vec_model[word]\n",
    "    except KeyError:\n",
    "        # Handle out-of-vocabulary (OOV) words (e.g., assign default vector or skip)\n",
    "        return None  # You can also return a zero vector here (np.zeros(word2vec_model.vector_size))\n",
    "\n",
    "def create_review_vectors(text, word2vec_model):\n",
    "    \"\"\"\n",
    "    Creates a list of word vectors for the cleaned text, handling OOV words.\n",
    "\n",
    "    Args:\n",
    "        text (str): The cleaned text review.\n",
    "        word2vec_model (gensim.models.keyed_vectors.KeyedVectors): The Word2Vec model.\n",
    "\n",
    "    Returns:\n",
    "        List[np.ndarray]: The list of word vectors for the review.\n",
    "    \"\"\"\n",
    "\n",
    "    cleaned_text = clean_text(text)\n",
    "    words = cleaned_text.split()\n",
    "    review_vectors = [get_word_vector(word, word2vec_model) for word in words]\n",
    "    return review_vectors\n",
    "\n",
    "# Define paths to positive and negative folders\n",
    "pos_train_folder = \"aclImdb/train/pos\"\n",
    "neg_train_folder = \"aclImdb/train/neg\"\n",
    "pos_test_folder = \"aclImdb/test/pos\"\n",
    "neg_test_folder = \"aclImdb/test/neg\"\n",
    "\n",
    "# Loop through each folder (positive and negative)\n",
    "for folder in [pos_train_folder, neg_train_folder, pos_test_folder, neg_test_folder]:\n",
    "    folder_path = os.path.join(os.getcwd(), folder)  # Get full folder path\n",
    "\n",
    "    # Loop through each text file in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".txt\"):  # Check for .txt files\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            # Read the text file\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                text = file.read()\n",
    "\n",
    "            # Clean the text\n",
    "            cleaned_text = clean_text(text)\n",
    "\n",
    "            # Split into words or sentences (choose one)\n",
    "            # Uncomment the desired option and comment out the other\n",
    "\n",
    "            # Split into words\n",
    "            words = split_into_words(cleaned_text)\n",
    "\n",
    "            # Split into sentences\n",
    "            # sentences = split_into_sentences(cleaned_text)\n",
    "            # print(f\"Sentences for {filename}: {sentences}\")\n",
    "            # Create review vectors (list of word vectors)\n",
    "            review_vectors = create_review_vectors(words, word2vec_model)\n",
    "\n",
    "            # Now you have the review_vectors list for each review, which you can use for sentiment analysis\n",
    "            # (e.g., by averaging the word vectors, using them as input to a machine learning model, etc.)\n",
    "\n",
    "print(\"Processing completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee5ed5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from gensim) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from gensim) (1.11.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Collecting FuzzyTM>=0.4.0 (from gensim)\n",
      "  Obtaining dependency information for FuzzyTM>=0.4.0 from https://files.pythonhosted.org/packages/2d/30/074bac7a25866a2807c1005c7852c0139ac22ba837871fc01f16df29b9dc/FuzzyTM-2.0.9-py3-none-any.whl.metadata\n",
      "  Using cached FuzzyTM-2.0.9-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from FuzzyTM>=0.4.0->gensim) (2.0.3)\n",
      "Collecting pyfume (from FuzzyTM>=0.4.0->gensim)\n",
      "  Obtaining dependency information for pyfume from https://files.pythonhosted.org/packages/f0/fe/b899a3d9a18c9a44a35155c79a4c152cb85990ea38ce6ab7ed73e5caa1b9/pyFUME-0.3.1-py3-none-any.whl.metadata\n",
      "  Using cached pyFUME-0.3.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2023.3)\n",
      "Collecting simpful (from pyfume->FuzzyTM>=0.4.0->gensim)\n",
      "  Obtaining dependency information for simpful from https://files.pythonhosted.org/packages/9d/0e/aebc2fb0b0f481994179b2ee2b8e6bbf0894d971594688c018375e7076ea/simpful-2.12.0-py3-none-any.whl.metadata\n",
      "  Using cached simpful-2.12.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting fst-pso (from pyfume->FuzzyTM>=0.4.0->gensim)\n",
      "  Using cached fst-pso-1.8.1.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (4.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->FuzzyTM>=0.4.0->gensim) (1.16.0)\n",
      "Collecting miniful (from fst-pso->pyfume->FuzzyTM>=0.4.0->gensim)\n",
      "  Using cached miniful-0.0.6.tar.gz (2.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Downloading FuzzyTM-2.0.9-py3-none-any.whl (31 kB)\n",
      "Downloading pyFUME-0.3.1-py3-none-any.whl (59 kB)\n",
      "   ---------------------------------------- 0.0/59.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 59.6/59.6 kB 1.0 MB/s eta 0:00:00\n",
      "Downloading simpful-2.12.0-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: fst-pso, miniful\n",
      "  Building wheel for fst-pso (setup.py): started\n",
      "  Building wheel for fst-pso (setup.py): finished with status 'done'\n",
      "  Created wheel for fst-pso: filename=fst_pso-1.8.1-py3-none-any.whl size=20448 sha256=6cfe03aaafe6719cccd12c55d7e940015244d68c573f48190dd87d33f7ea8a84\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\69\\f5\\e5\\18ad53fe1ed6b2af9fad05ec052e4acbac8e92441df44bad2e\n",
      "  Building wheel for miniful (setup.py): started\n",
      "  Building wheel for miniful (setup.py): finished with status 'done'\n",
      "  Created wheel for miniful: filename=miniful-0.0.6-py3-none-any.whl size=3522 sha256=28093b4e1a024bee248d6050014a86df31be180b12d54b748ad737a5a1f13a7c\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\9d\\ff\\2f\\afe4cd56f47de147407705626517d68bea0f3b74eb1fb168e6\n",
      "Successfully built fst-pso miniful\n",
      "Installing collected packages: simpful, miniful, fst-pso, pyfume, FuzzyTM\n",
      "Successfully installed FuzzyTM-2.0.9 fst-pso-1.8.1 miniful-0.0.6 pyfume-0.3.1 simpful-2.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5102cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
